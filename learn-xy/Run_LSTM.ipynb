{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import gc\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import progressbar as pb\n",
    "import sklearn.utils as sku\n",
    "\n",
    "import Config as conf\n",
    "import CSV as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing CSV files...\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_001.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_002.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_003.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_004.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_005.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_006.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_007.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_008.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_009.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_010.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_011.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_012.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_013.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_014.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_015.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_016.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_017.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_018.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_019.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_020.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/csi_021.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_001.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_002.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_003.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_004.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_005.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_006.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_007.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_008.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_009.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_010.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_011.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_012.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_013.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_014.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_015.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_016.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_017.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_018.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_019.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_020.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH85/action_021.csv\n",
      " -- Reshaping xx ...\n",
      " -- Shape notice: [xx] (4158, 3760, 90) [yy] (4158, 2)\n",
      " -- Using No-Activity window.\n",
      "Loaded CSVs\n"
     ]
    }
   ],
   "source": [
    "# Import & shuffle CSV data\n",
    "xx, yy = csv.getCSV()\n",
    "xx, yy = sku.shuffle(xx, yy, random_state=0)\n",
    "xo, yo = xx, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import keras.callbacks as kc\n",
    "import keras.layers as kl\n",
    "import keras.models as km\n",
    "import keras.optimizers as ko\n",
    "import keras.utils as ku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GC Collected: 0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 540)               1362960   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1082      \n",
      "=================================================================\n",
      "Total params: 1,364,042\n",
      "Trainable params: 1,364,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Setup Keras VGG16 Model\n",
    "print(\"GC Collected:\", gc.collect())\n",
    "adam = ko.Adam(lr=conf.LEARNING_RATE, amsgrad=True)\n",
    "lstm = kl.LSTM(\n",
    "    conf.N_HIDDEN,\n",
    "    unit_forget_bias=True,\n",
    "    input_shape=(conf.WINDOW_SIZE, conf.N_COLUMNS))\n",
    "lstm.add_loss(1e-8)\n",
    "model = km.Sequential()\n",
    "model.add(lstm)\n",
    "model.add(\n",
    "    kl.Dense(\n",
    "        conf.USE_NOACTIVITY and conf.N_CLASSES or conf.N_VALID_CLASSES,\n",
    "    activation=\"softmax\"))\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=adam,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you have tensorboard in this environment, you can type below to see the result in tensorboard:\n",
      "    tensorboard --logdir=./Log_LR0.002_BATCH48_GWRRATE80/\n",
      "Keras checkpoints and final result will be saved in here:\n",
      "    ./Output_LR0.002_BATCH48_GWRRATE80/\n"
     ]
    }
   ],
   "source": [
    "# Check output directory and prepare tensorboard\n",
    "conf.BATCH_SIZE = 48\n",
    "outputDir = conf.OUTPUT_PATH.format(conf.LEARNING_RATE, conf.BATCH_SIZE,\n",
    "                                    conf.N_FILTERS, \"\")\n",
    "if os.path.exists(outputDir):\n",
    "    shutil.rmtree(outputDir)\n",
    "os.makedirs(outputDir)\n",
    "logDir = conf.LOG_PATH.format(conf.LEARNING_RATE, conf.BATCH_SIZE,\n",
    "                              conf.N_FILTERS, \"\")\n",
    "if os.path.exists(logDir):\n",
    "    shutil.rmtree(logDir)\n",
    "os.makedirs(logDir)\n",
    "tensorboard = kc.TensorBoard(\n",
    "    log_dir=logDir,\n",
    "    histogram_freq=0,\n",
    "    batch_size=conf.BATCH_SIZE,\n",
    "    write_graph=True,\n",
    "    write_grads=True,\n",
    "    write_images=True,\n",
    "    update_freq=10)\n",
    "print(\n",
    "    \"If you have tensorboard in this environment, you can type below to see the result in tensorboard:\"\n",
    ")\n",
    "print(\"    tensorboard --logdir=\" + logDir)\n",
    "print(\"Keras checkpoints and final result will be saved in here:\")\n",
    "print(\"    \" + outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (4158 of 4158) |####################| Elapsed Time: 0:00:35 Time:  0:00:35\n",
      "N/A% (0 of 627) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Activity Y: 209\n",
      "Will find 627 Non-Activity windows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (627 of 627) |######################| Elapsed Time: 0:05:45 Time:  0:05:45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Ratio Modified, Final Shape: [xx] (837, 3760, 90) [yy] (837, 2)\n"
     ]
    }
   ],
   "source": [
    "# Modify activity:non-activity ratio\n",
    "conf.ANOA_RATIO = 3\n",
    "if conf.USE_NOACTIVITY:\n",
    "    xx = np.empty([0, conf.WINDOW_SIZE, conf.N_COLUMNS], float)\n",
    "    yy = np.empty([0, conf.N_CLASSES], float)\n",
    "    with pb.ProgressBar(max_value=len(yo)) as bar:\n",
    "        bar.update(0)\n",
    "        for i in range(len(yo)):\n",
    "            if yo[i, 0] == 0:\n",
    "                yy = np.concatenate((yy, yo[i, :][np.newaxis, ...]), axis=0)\n",
    "                xx = np.concatenate((xx, xo[i, :][np.newaxis, ...]), axis=0)\n",
    "            bar.update(i)\n",
    "    print(\"Found Activity Y:\", len(yy))\n",
    "    noacmx = int(len(yy) * conf.ANOA_RATIO)\n",
    "    print(\"Will find\", noacmx, \"Non-Activity windows\")\n",
    "    noac = 0\n",
    "    with pb.ProgressBar(max_value=noacmx) as bar:\n",
    "        bar.update(0)\n",
    "        for i in range(len(yo)):\n",
    "            if noac > noacmx:\n",
    "                break\n",
    "            if not yo[i, 0] == 0:\n",
    "                yy = np.concatenate((yy, yo[i, :][np.newaxis, ...]), axis=0)\n",
    "                xx = np.concatenate((xx, xo[i, :][np.newaxis, ...]), axis=0)\n",
    "                bar.update(noac)\n",
    "                noac += 1\n",
    "    print(\"Input Ratio Modified, Final Shape: [xx]\", xx.shape, \"[yy]\", yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabage Collecting Time! => 18\n",
      "1 th fitting started. Endpoint is 8 th.\n",
      "WARNING:tensorflow:From /home/iknowme/anaconda3/envs/ppp/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 733 samples, validate on 104 samples\n",
      "Epoch 1/256\n"
     ]
    }
   ],
   "source": [
    "# Run KFold\n",
    "conf.KFOLD = 8\n",
    "conf.BATCH_SIZE = 48\n",
    "conf.CP_PERIOD = 1\n",
    "conf.N_EPOCH = 256\n",
    "xx, yy = sku.shuffle(xx, yy, random_state=0)\n",
    "for i in range(conf.KFOLD):\n",
    "    # Run Garbage Collector\n",
    "    print(\"Grabage Collecting Time! =>\", gc.collect())\n",
    "    \n",
    "    # Roll the data\n",
    "    xx = np.roll(xx, int(len(xx) / conf.KFOLD), axis=0)\n",
    "    yy = np.roll(yy, int(len(yy) / conf.KFOLD), axis=0)\n",
    "\n",
    "    # Data separation\n",
    "    xTrain = xx[int(len(xx) / conf.KFOLD):]\n",
    "    yTrain = yy[int(len(yy) / conf.KFOLD):]\n",
    "    xEval = xx[:int(len(xx) / conf.KFOLD)]\n",
    "    yEval = yy[:int(len(yy) / conf.KFOLD)]\n",
    "\n",
    "    if not conf.USE_NOACTIVITY:\n",
    "        # Remove NoActivity from ys\n",
    "        yTrain = yTrain[:, 1:]\n",
    "        yEval = yEval[:, 1:]\n",
    "\n",
    "        # If there exists only one action, convert Y to binary form\n",
    "        if yEval.shape[1] == 1:\n",
    "            yTrain = ku.to_categorical(yTrain)\n",
    "            yEval = ku.to_categorical(yEval)\n",
    "\n",
    "    # Setup Keras Checkpoint\n",
    "    checkpoint = kc.ModelCheckpoint(\n",
    "        outputDir + \"Checkpoint_K\" + str(i + 1) + \"_EPOCH{epoch}_ACC{val_acc:.6f}.h5\", period=conf.CP_PERIOD)\n",
    "\n",
    "    # Fit model (learn)\n",
    "    print(\n",
    "        str(i + 1) + \" th fitting started. Endpoint is \" + str(conf.KFOLD) +\n",
    "        \" th.\")\n",
    "\n",
    "    model.fit(\n",
    "        xTrain,\n",
    "        yTrain,\n",
    "        batch_size=conf.BATCH_SIZE,\n",
    "        epochs=conf.N_EPOCH,\n",
    "        verbose=1,\n",
    "        callbacks=[tensorboard, checkpoint],\n",
    "        validation_data=(xEval, yEval))  # , validation_freq=2)\n",
    "print(\"Epoch completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "print(\"Saving model & model information...\")\n",
    "modelYML = model.to_yaml()\n",
    "with open(outputDir + \"model.yml\", \"w\") as yml:\n",
    "    yml.write(modelYML)\n",
    "modelJSON = model.to_json()\n",
    "with open(outputDir + \"model.json\", \"w\") as json:\n",
    "    json.write(modelJSON)\n",
    "model.save(outputDir + \"model.h5\")\n",
    "print('Model saved! Congratulations! You finished all processes of ML!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finished"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

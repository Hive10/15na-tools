{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import gc\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import keras.callbacks as kc\n",
    "import keras.optimizers as ko\n",
    "import keras.utils as ku\n",
    "import numpy as np\n",
    "import sklearn.utils as sku\n",
    "import tensorflow as tf\n",
    "\n",
    "import Config as conf\n",
    "import CSV as csv\n",
    "from DenseNet import DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing CSV files...\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_001.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_002.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_003.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_004.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_005.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_006.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_007.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_008.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_009.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_010.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_011.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_012.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_013.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_014.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_015.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_016.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_017.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_018.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_019.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_020.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_021.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_022.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_023.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_024.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_025.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_026.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_027.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_028.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/csi_029.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_001.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_002.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_003.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_004.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_005.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_006.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_007.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_008.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_009.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_010.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_011.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_012.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_013.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_014.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_015.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_016.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_017.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_018.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_019.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_020.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_021.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_022.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_023.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_024.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_025.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_026.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_027.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_028.csv\n",
      " -- Loading: ./Input_WINDOW3760_COL90_TH95/action_029.csv\n",
      " -- Reshaping xx ...\n",
      " -- Shape notice: [xx] (5712, 3760, 90) [yy] (5712, 2)\n",
      " -- Using No-Activity window.\n",
      "Loaded CSVs\n"
     ]
    }
   ],
   "source": [
    "# Import & shuffle CSV data\n",
    "xx, yy = csv.getCSV()\n",
    "xx, yy = sku.shuffle(xx, yy, random_state=0)\n",
    "xx = xx[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GC Collected: 492\n",
      "Creating DenseNet 0.0.3\n",
      "#############################################\n",
      "Dense blocks: 2\n",
      "Layers per dense block: [6, 6]\n",
      "#############################################\n"
     ]
    }
   ],
   "source": [
    "# Setup Keras DenseNet Model (DenseNet-BC)\n",
    "conf.N_FILTERS = 40\n",
    "conf.DEPTH = 40\n",
    "print(\"GC Collected:\", gc.collect())\n",
    "tfOptions = tf.RunOptions(report_tensor_allocations_upon_oom=True)\n",
    "nadam = ko.Nadam(lr=conf.LEARNING_RATE)\n",
    "model = DenseNet(\n",
    "    input_shape=(conf.WINDOW_SIZE, conf.N_COLUMNS, 1),\n",
    "    dense_blocks=2,\n",
    "    growth_rate=conf.N_FILTERS,\n",
    "    nb_classes=conf.USE_NOACTIVITY and conf.N_CLASSES or conf.N_VALID_CLASSES,\n",
    "    dropout_rate=0.2,\n",
    "    bottleneck=True,\n",
    "    compression=0.5,\n",
    "    weight_decay=1e-4,\n",
    "    depth=conf.DEPTH\n",
    ").build_model()\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=nadam,\n",
    "    metrics=[\"accuracy\"],\n",
    "    options=tfOptions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you have tensorboard in this environment, you can type below to see the result in tensorboard:\n",
      "    tensorboard --logdir=./Log_LR0.002_BATCH64_GWRRATE40/\n",
      "Keras checkpoints and final result will be saved in here:\n",
      "    ./Output_LR0.002_BATCH64_GWRRATE40/\n"
     ]
    }
   ],
   "source": [
    "# Check output directory and prepare tensorboard\n",
    "outputDir = conf.OUTPUT_PATH.format(conf.LEARNING_RATE, conf.BATCH_SIZE,\n",
    "                                    conf.N_FILTERS, \"\")\n",
    "if os.path.exists(outputDir):\n",
    "    shutil.rmtree(outputDir)\n",
    "os.makedirs(outputDir)\n",
    "logDir = conf.LOG_PATH.format(conf.LEARNING_RATE, conf.BATCH_SIZE,\n",
    "                              conf.N_FILTERS, \"\")\n",
    "if os.path.exists(logDir):\n",
    "    shutil.rmtree(logDir)\n",
    "os.makedirs(logDir)\n",
    "tensorboard = kc.TensorBoard(\n",
    "    log_dir=logDir,\n",
    "    histogram_freq=0,\n",
    "    batch_size=conf.BATCH_SIZE,\n",
    "    write_graph=True,\n",
    "    write_grads=True,\n",
    "    write_images=True,\n",
    "    update_freq=10)\n",
    "print(\n",
    "    \"If you have tensorboard in this environment, you can type below to see the result in tensorboard:\"\n",
    ")\n",
    "print(\"    tensorboard --logdir=\" + logDir)\n",
    "print(\"Keras checkpoints and final result will be saved in here:\")\n",
    "print(\"    \" + outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 th fitting started. Endpoint is 10 th.\n",
      "Train on 5141 samples, validate on 571 samples\n",
      "Epoch 1/512\n"
     ]
    }
   ],
   "source": [
    "# Run KFold\n",
    "conf.KFOLD = 10\n",
    "conf.BATCH_SIZE = 1\n",
    "for i in range(conf.KFOLD):\n",
    "    # Roll the data\n",
    "    xx = np.roll(xx, int(len(xx) / conf.KFOLD), axis=0)\n",
    "    yy = np.roll(yy, int(len(yy) / conf.KFOLD), axis=0)\n",
    "\n",
    "    # Data separation\n",
    "    xTrain = xx[int(len(xx) / conf.KFOLD):]\n",
    "    yTrain = yy[int(len(yy) / conf.KFOLD):]\n",
    "    xEval = xx[:int(len(xx) / conf.KFOLD)]\n",
    "    yEval = yy[:int(len(yy) / conf.KFOLD)]\n",
    "\n",
    "    if not conf.USE_NOACTIVITY:\n",
    "        # Remove NoActivity from ys\n",
    "        yTrain = yTrain[:, 1:]\n",
    "        yEval = yEval[:, 1:]\n",
    "\n",
    "        # If there exists only one action, convert Y to binary form\n",
    "        if yEval.shape[1] == 1:\n",
    "            yTrain = ku.to_categorical(yTrain)\n",
    "            yEval = ku.to_categorical(yEval)\n",
    "\n",
    "    # Setup Keras Checkpoint\n",
    "    checkpoint = kc.ModelCheckpoint(\n",
    "        outputDir + \"Checkpoint_K\" + str(i + 1) + \"_EPOCH{epoch}_ACC{val_acc:.6f}.h5\", period=conf.CP_PERIOD)\n",
    "\n",
    "    # Fit model (learn)\n",
    "    print(\n",
    "        str(i + 1) + \" th fitting started. Endpoint is \" + str(conf.KFOLD) +\n",
    "        \" th.\")\n",
    "\n",
    "    model.fit(\n",
    "        xTrain,\n",
    "        yTrain,\n",
    "        batch_size=conf.BATCH_SIZE,\n",
    "        epochs=conf.N_EPOCH,\n",
    "        verbose=1,\n",
    "        callbacks=[tensorboard, checkpoint],\n",
    "        validation_data=(xEval, yEval))  # , validation_freq=2)\n",
    "print(\"Epoch completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "print(\"Saving model & model information...\")\n",
    "modelYML = model.to_yaml()\n",
    "with open(outputDir + \"model.yml\", \"w\") as yml:\n",
    "    yml.write(modelYML)\n",
    "modelJSON = model.to_json()\n",
    "with open(outputDir + \"model.json\", \"w\") as json:\n",
    "    json.write(modelJSON)\n",
    "model.save(outputDir + \"model.h5\")\n",
    "print('Model saved! Congratulations! You finished all processes of ML!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finished"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import keras.callbacks as kc\n",
    "import keras.layers as kl\n",
    "import keras.models as km\n",
    "import keras.optimizers as ko\n",
    "import keras.utils as ku\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import sklearn.utils as sku\n",
    "\n",
    "import Config as conf\n",
    "import CSV as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output directory\n",
    "outputDir = conf.OUTPUT_PATH.format(conf.LEARNING_RATE, conf.BATCH_SIZE,\n",
    "                                    conf.N_HIDDEN, \"\")\n",
    "if os.path.exists(outputDir):\n",
    "    shutil.rmtree(outputDir)\n",
    "os.makedirs(outputDir)\n",
    "logDir = conf.LOG_PATH.format(conf.LEARNING_RATE, conf.BATCH_SIZE,\n",
    "                              conf.N_HIDDEN, \"\")\n",
    "if os.path.exists(logDir):\n",
    "    shutil.rmtree(logDir)\n",
    "os.makedirs(logDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you have tensorboard in this environment, you can type below to see the result in tensorboard:\n",
      "    tensorboard --logdir=./Log_LR0.0001_BATCH64_HIDDEN540/\n"
     ]
    }
   ],
   "source": [
    "# Setup Keras Callbacks\n",
    "tensorboard = kc.TensorBoard(\n",
    "    log_dir=logDir,\n",
    "    histogram_freq=0,\n",
    "    batch_size=conf.BATCH_SIZE,\n",
    "    write_graph=True,\n",
    "    write_grads=True,\n",
    "    write_images=True,\n",
    "    update_freq=10)\n",
    "print(\n",
    "    \"If you have tensorboard in this environment, you can type below to see the result in tensorboard:\"\n",
    ")\n",
    "print(\"    tensorboard --logdir=\" + logDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras checkpoints and final result will be saved in here:\n",
      "    ./Output_LR0.0001_BATCH64_HIDDEN540/\n"
     ]
    }
   ],
   "source": [
    "# Notice Checkpoint Directory\n",
    "print(\"Keras checkpoints and final result will be saved in here:\")\n",
    "print(\"    \" + outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chish\\.conda\\envs\\ppp\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Setup Keras RNN Model\n",
    "lstm = kl.LSTM(\n",
    "    conf.N_HIDDEN,\n",
    "    unit_forget_bias=True,\n",
    "    input_shape=(conf.N_STEPS, conf.N_INPUT))\n",
    "lstm.add_loss(1e-8)\n",
    "adam = ko.Adam(lr=conf.LEARNING_RATE, amsgrad=True)\n",
    "model = km.Sequential()\n",
    "model.add(lstm)\n",
    "model.add(kl.Dense(\n",
    "    conf.USE_NOACTIVITY and conf.N_CLASSES or conf.N_VALID_CLASSES, activation=\"softmax\"))\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input directory not found. Calculate merged CSVs...\n",
      "About enh1 ...\n",
      "Processing X:  ./Dataset\\csi_enh1_1.csv\n",
      "Processing X:  ./Dataset\\csi_enh1_2.csv\n",
      "Processing X:  ./Dataset\\csi_enh1_3.csv\n",
      "Processing Y:  ./Dataset\\action_enh1_1.csv\n",
      "Processing Y:  ./Dataset\\action_enh1_2.csv\n",
      "Processing Y:  ./Dataset\\action_enh1_3.csv\n",
      "(2254, 108000) (2254, 4)\n",
      "Writing calculated X/Ys ...\n",
      "==== Action \"enh1\" Finished! ====\n",
      "About enh2 ...\n",
      "Processing X:  ./Dataset\\csi_enh2_1.csv\n",
      "Processing X:  ./Dataset\\csi_enh2_2.csv\n",
      "Processing X:  ./Dataset\\csi_enh2_3.csv\n",
      "Processing X:  ./Dataset\\csi_enh2_4.csv\n",
      "Processing Y:  ./Dataset\\action_enh2_1.csv\n",
      "Processing Y:  ./Dataset\\action_enh2_2.csv\n",
      "Processing Y:  ./Dataset\\action_enh2_3.csv\n",
      "(1338, 108000) (973, 4)\n",
      "Writing calculated X/Ys ...\n",
      "==== Action \"enh2\" Finished! ====\n",
      "About syncope ...\n",
      "Processing X:  ./Dataset\\csi_syncope_1.csv\n",
      "Processing X:  ./Dataset\\csi_syncope_10.csv\n",
      "Processing X:  ./Dataset\\csi_syncope_2.csv\n",
      "Processing X:  ./Dataset\\csi_syncope_3.csv\n",
      "Processing X:  ./Dataset\\csi_syncope_4.csv\n",
      "Processing X:  ./Dataset\\csi_syncope_5.csv\n",
      "Processing X:  ./Dataset\\csi_syncope_6.csv\n",
      "Processing X:  ./Dataset\\csi_syncope_7.csv\n",
      "Processing X:  ./Dataset\\csi_syncope_8.csv\n",
      "Processing X:  ./Dataset\\csi_syncope_9.csv\n",
      "Processing Y:  ./Dataset\\action_syncope_1.csv\n",
      "Processing Y:  ./Dataset\\action_syncope_10.csv\n",
      "Processing Y:  ./Dataset\\action_syncope_2.csv\n",
      "Processing Y:  ./Dataset\\action_syncope_3.csv\n",
      "Processing Y:  ./Dataset\\action_syncope_4.csv\n",
      "Processing Y:  ./Dataset\\action_syncope_5.csv\n",
      "Processing Y:  ./Dataset\\action_syncope_6.csv\n",
      "Processing Y:  ./Dataset\\action_syncope_7.csv\n",
      "Processing Y:  ./Dataset\\action_syncope_8.csv\n",
      "Processing Y:  ./Dataset\\action_syncope_9.csv\n",
      "(1550, 108000) (1550, 4)\n",
      "Writing calculated X/Ys ...\n",
      "==== Action \"syncope\" Finished! ====\n",
      "Calculation finished!\n",
      "CSV data automatically imported from cache.\n",
      "[1 / 4] enh1 taken from cache... xx= (2254, 108000) yy= (2254, 4)\n",
      "[2 / 4] Eliminating No-Activity windows of enh1 ...\n",
      "[2 / 4] Eliminating No-Activity windows of enh1 finished\n",
      "[3 / 4] Reshaping enh1 ...\n",
      "[3 / 4] Reshaping enh1 finished... xx= (383, 1200, 90) yy= (383, 4)\n",
      "[4 / 4] Garbage collecting...\n",
      "[4 / 4] Garbage collecting finished\n",
      "[1 / 4] enh2 taken from cache... xx= (1338, 108000) yy= (973, 4)\n",
      "[2 / 4] Eliminating No-Activity windows of enh2 ...\n",
      "[2 / 4] Eliminating No-Activity windows of enh2 finished\n",
      "[3 / 4] Reshaping enh2 ...\n",
      "[3 / 4] Reshaping enh2 finished... xx= (611, 1200, 90) yy= (246, 4)\n",
      "[4 / 4] Garbage collecting...\n",
      "[4 / 4] Garbage collecting finished\n",
      "[1 / 4] syncope taken from cache... xx= (1550, 108000) yy= (1550, 4)\n",
      "[2 / 4] Eliminating No-Activity windows of syncope ...\n",
      "[2 / 4] Eliminating No-Activity windows of syncope finished\n",
      "[3 / 4] Reshaping syncope ...\n",
      "[3 / 4] Reshaping syncope finished... xx= (87, 1200, 90) yy= (87, 4)\n",
      "[4 / 4] Garbage collecting...\n",
      "[4 / 4] Garbage collecting finished\n",
      "Loading CSV finished!\n"
     ]
    }
   ],
   "source": [
    "# Import CSV data\n",
    "xs, ys = csv.getCSV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [611, 246]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-2ba478f2ab79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Shuffle data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACTIONS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msku\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\ppp\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36mshuffle\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \"\"\"\n\u001b[0;32m    402\u001b[0m     \u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ppp\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m    314\u001b[0m                                                     n_samples))\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ppp\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 235\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [611, 246]"
     ]
    }
   ],
   "source": [
    "# Shuffle data\n",
    "for a in conf.ACTIONS:\n",
    "    xs[a], ys[a] = sku.shuffle(xs[a], ys[a], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run KFold\n",
    "for i in range(conf.KFOLD):\n",
    "    # Roll the data\n",
    "    for a in conf.ACTIONS:\n",
    "        xs[a] = np.roll(xs[a], int(len(xs[a]) / conf.KFOLD), axis=0)\n",
    "        ys[a] = np.roll(ys[a], int(len(ys[a]) / conf.KFOLD), axis=0)\n",
    "\n",
    "    # Data separation\n",
    "    xTrain = []\n",
    "    yTrain = []\n",
    "    xEval = []\n",
    "    yEval = []\n",
    "    for a in conf.ACTIONS:\n",
    "        if xTrain == []:\n",
    "            xTrain = xs[a][int(len(xs[a]) / conf.KFOLD):]\n",
    "        else:\n",
    "            xTrain = np.r_[xTrain, xs[a][int(len(xs[a]) / conf.KFOLD):]]\n",
    "        if yTrain == []:\n",
    "            yTrain = ys[a][int(len(ys[a]) / conf.KFOLD):]\n",
    "        else:\n",
    "            yTrain = np.r_[yTrain, ys[a][int(len(ys[a]) / conf.KFOLD):]]\n",
    "        if xEval == []:\n",
    "            xEval = xs[a][:int(len(xs[a]) / conf.KFOLD)]\n",
    "        else:\n",
    "            xEval = np.r_[xEval, xs[a][:int(len(xs[a]) / conf.KFOLD)]]\n",
    "        if yEval == []:\n",
    "            yEval = ys[a][:int(len(ys[a]) / conf.KFOLD)]\n",
    "        else:\n",
    "            yEval = np.r_[yEval, ys[a][:int(len(ys[a]) / conf.KFOLD)]]\n",
    "\n",
    "    if not conf.USE_NOACTIVITY:\n",
    "        # Remove NoActivity from ys\n",
    "        yTrain = yTrain[:, 1:]\n",
    "        yEval = yEval[:, 1:]\n",
    "\n",
    "        # If there exists only one action, convert Y to binary form\n",
    "        if yEval.shape[1] == 1:\n",
    "            yTrain = ku.to_categorical(yTrain)\n",
    "            yEval = ku.to_categorical(yEval)\n",
    "\n",
    "    # Setup Keras Checkpoint\n",
    "    checkpoint = kc.ModelCheckpoint(\n",
    "        outputDir + \"Checkpoint_K\" + str(i) + \"_EPOCH{epoch}_ACC{val_acc:.4f}.h5\", period=25)\n",
    "\n",
    "    # Fit model (learn)\n",
    "    print(\n",
    "        str(i) + \" th fitting started. Endpoint is \" + str(conf.KFOLD) +\n",
    "        \" th.\")\n",
    "\n",
    "    model.fit(\n",
    "        xTrain,\n",
    "        yTrain,\n",
    "        batch_size=conf.BATCH_SIZE,\n",
    "        epochs=conf.N_ITERATIONS,\n",
    "        verbose=1,\n",
    "        callbacks=[tensorboard, checkpoint],\n",
    "        validation_data=(xEval, yEval))  #, validation_freq=2)\n",
    "print(\"Epoch completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "print(\"Saving model & model information...\")\n",
    "modelYML = model.to_yaml()\n",
    "with open(outputDir + \"model.yml\", \"w\") as yml:\n",
    "    yml.write(modelYML)\n",
    "modelJSON = model.to_json()\n",
    "with open(outputDir + \"model.json\", \"w\") as json:\n",
    "    json.write(modelJSON)\n",
    "model.save(outputDir + \"model.h5\")\n",
    "print('Model saved! Congratulations! You finished all processes of ML!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finished"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

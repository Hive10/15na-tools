{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import keras.callbacks as kc\n",
    "import keras.layers as kl\n",
    "import keras.models as km\n",
    "import keras.optimizers as ko\n",
    "import keras.utils as ku\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import sklearn.utils as sku\n",
    "\n",
    "import Config as conf\n",
    "import CSV as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output directory\n",
    "outputDir = conf.OUTPUT_PATH.format(conf.LEARNING_RATE, conf.BATCH_SIZE,\n",
    "                                    conf.N_HIDDEN, \"\")\n",
    "if os.path.exists(outputDir):\n",
    "    shutil.rmtree(outputDir)\n",
    "os.makedirs(outputDir)\n",
    "logDir = conf.LOG_PATH.format(conf.LEARNING_RATE, conf.BATCH_SIZE,\n",
    "                              conf.N_HIDDEN, \"\")\n",
    "if os.path.exists(logDir):\n",
    "    shutil.rmtree(logDir)\n",
    "os.makedirs(logDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you have tensorboard in this environment, you can type below to see the result in tensorboard:\n",
      "    tensorboard --logdir=./Log_LR1e-05_BATCH16_HIDDEN1024/\n"
     ]
    }
   ],
   "source": [
    "# Setup Keras Callbacks\n",
    "tensorboard = kc.TensorBoard(\n",
    "    log_dir=logDir,\n",
    "    histogram_freq=0,\n",
    "    batch_size=conf.BATCH_SIZE,\n",
    "    write_graph=True,\n",
    "    write_grads=True,\n",
    "    write_images=True,\n",
    "    update_freq=10)\n",
    "print(\n",
    "    \"If you have tensorboard in this environment, you can type below to see the result in tensorboard:\"\n",
    ")\n",
    "print(\"    tensorboard --logdir=\" + logDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras checkpoints and final result will be saved in here:\n",
      "    ./Output_LR1e-05_BATCH16_HIDDEN1024/\n"
     ]
    }
   ],
   "source": [
    "# Notice Checkpoint Directory\n",
    "print(\"Keras checkpoints and final result will be saved in here:\")\n",
    "print(\"    \" + outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chish\\.conda\\envs\\ppp\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Setup Keras RNN Model\n",
    "lstm = kl.LSTM(\n",
    "    conf.N_HIDDEN,\n",
    "    input_shape=(conf.WINDOW_SIZE, conf.N_COLUMNS))\n",
    "lstm.add_loss(1e-8)\n",
    "adam = ko.Adam(lr=conf.LEARNING_RATE, amsgrad=True)\n",
    "model = km.Sequential()\n",
    "model.add(lstm)\n",
    "model.add(kl.Dense(\n",
    "    conf.USE_NOACTIVITY and conf.N_CLASSES or conf.N_VALID_CLASSES, activation=\"softmax\"))\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input directory not found. Calculate merged CSVs...\n",
      "About noa ...\n",
      "Processing X:  ./Dataset\\csi_noa_1.csv\n",
      "Processing X:  ./Dataset\\csi_noa_2.csv\n",
      "Processing Y:  ./Dataset\\action_noa_1.csv\n",
      "Processing Y:  ./Dataset\\action_noa_2.csv\n",
      "(1092, 169200) (1092, 3)\n",
      "Writing calculated X/Ys ...\n",
      "==== Action \"noa\" Finished! ====\n",
      "About syncope ...\n",
      "Processing X:  ./Dataset\\csi_syncope_1.csv\n",
      "Processing X:  ./Dataset\\csi_syncope_2.csv\n",
      "Processing X:  ./Dataset\\csi_syncope_3.csv\n",
      "Processing X:  ./Dataset\\csi_syncope_4.csv\n",
      "Processing X:  ./Dataset\\csi_syncope_5.csv\n",
      "Processing X:  ./Dataset\\csi_syncope_6.csv\n",
      "Processing X:  ./Dataset\\csi_syncope_7.csv\n",
      "Processing X:  ./Dataset\\csi_syncope_8.csv\n",
      "Processing X:  ./Dataset\\csi_syncope_9.csv\n",
      "Processing Y:  ./Dataset\\action_syncope_1.csv\n",
      "Processing Y:  ./Dataset\\action_syncope_2.csv\n",
      "Processing Y:  ./Dataset\\action_syncope_3.csv\n",
      "Processing Y:  ./Dataset\\action_syncope_4.csv\n",
      "Processing Y:  ./Dataset\\action_syncope_5.csv\n",
      "Processing Y:  ./Dataset\\action_syncope_6.csv\n",
      "Processing Y:  ./Dataset\\action_syncope_7.csv\n",
      "Processing Y:  ./Dataset\\action_syncope_8.csv\n",
      "Processing Y:  ./Dataset\\action_syncope_9.csv\n",
      "(1712, 169200) (1712, 3)\n",
      "Writing calculated X/Ys ...\n",
      "==== Action \"syncope\" Finished! ====\n",
      "Calculation finished!\n",
      "CSV data automatically imported from cache.\n",
      "[1 / 4] noa taken from cache... xx= (1092, 169200) yy= (1092, 3)\n",
      "[2 / 4] Eliminating No-Activity windows of noa ...\n",
      "[2 / 4] Eliminating No-Activity windows of noa finished\n",
      "[3 / 4] Reshaping noa ...\n",
      "[3 / 4] Reshaping noa finished... xx= (765, 1880, 90) yy= (765, 3)\n",
      "[4 / 4] Garbage collecting...\n",
      "[4 / 4] Garbage collecting finished\n",
      "[1 / 4] syncope taken from cache... xx= (1712, 169200) yy= (1712, 3)\n",
      "[2 / 4] Eliminating No-Activity windows of syncope ...\n",
      "[2 / 4] Eliminating No-Activity windows of syncope finished\n",
      "[3 / 4] Reshaping syncope ...\n",
      "[3 / 4] Reshaping syncope finished... xx= (302, 1880, 90) yy= (302, 3)\n",
      "[4 / 4] Garbage collecting...\n",
      "[4 / 4] Garbage collecting finished\n",
      "Loading CSV finished!\n"
     ]
    }
   ],
   "source": [
    "# Import CSV data\n",
    "xs, ys = csv.getCSV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "for a in conf.ACTIONS:\n",
    "    xs[a], ys[a] = sku.shuffle(xs[a], ys[a], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chish\\.conda\\envs\\ppp\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 th fitting started. Endpoint is 11 th.\n",
      "WARNING:tensorflow:From C:\\Users\\chish\\.conda\\envs\\ppp\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chish\\.conda\\envs\\ppp\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "C:\\Users\\chish\\.conda\\envs\\ppp\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "C:\\Users\\chish\\.conda\\envs\\ppp\\lib\\site-packages\\ipykernel_launcher.py:26: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 971 samples, validate on 96 samples\n",
      "Epoch 1/128\n",
      "971/971 [==============================] - 179s 185ms/step - loss: 0.3727 - acc: 0.8239 - val_loss: 0.1729 - val_acc: 0.9375\n",
      "Epoch 2/128\n",
      "971/971 [==============================] - 177s 182ms/step - loss: 0.1642 - acc: 0.9382 - val_loss: 0.1418 - val_acc: 0.9375\n",
      "Epoch 3/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.1375 - acc: 0.9464 - val_loss: 0.1246 - val_acc: 0.9375\n",
      "Epoch 4/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.1193 - acc: 0.9547 - val_loss: 0.1165 - val_acc: 0.9479\n",
      "Epoch 5/128\n",
      "971/971 [==============================] - 174s 179ms/step - loss: 0.1094 - acc: 0.9588 - val_loss: 0.1084 - val_acc: 0.9479\n",
      "Epoch 6/128\n",
      "971/971 [==============================] - 174s 180ms/step - loss: 0.0983 - acc: 0.9609 - val_loss: 0.1015 - val_acc: 0.9583\n",
      "Epoch 7/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0892 - acc: 0.9701 - val_loss: 0.0914 - val_acc: 0.9688\n",
      "Epoch 8/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0773 - acc: 0.9722 - val_loss: 0.0748 - val_acc: 0.9688\n",
      "Epoch 9/128\n",
      "971/971 [==============================] - 176s 181ms/step - loss: 0.0690 - acc: 0.9753 - val_loss: 0.0820 - val_acc: 0.9688\n",
      "Epoch 10/128\n",
      "971/971 [==============================] - 174s 180ms/step - loss: 0.0647 - acc: 0.9794 - val_loss: 0.0642 - val_acc: 0.9688\n",
      "Epoch 11/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0525 - acc: 0.9846 - val_loss: 0.0597 - val_acc: 0.9792\n",
      "Epoch 12/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0480 - acc: 0.9887 - val_loss: 0.0558 - val_acc: 0.9688\n",
      "Epoch 13/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0458 - acc: 0.9876 - val_loss: 0.0516 - val_acc: 0.9688\n",
      "Epoch 14/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0392 - acc: 0.9918 - val_loss: 0.0517 - val_acc: 0.9688\n",
      "Epoch 15/128\n",
      "971/971 [==============================] - 174s 179ms/step - loss: 0.0283 - acc: 0.9990 - val_loss: 0.0359 - val_acc: 0.9792\n",
      "Epoch 16/128\n",
      "971/971 [==============================] - 176s 181ms/step - loss: 0.0341 - acc: 0.9938 - val_loss: 0.0510 - val_acc: 0.9896\n",
      "Epoch 17/128\n",
      "971/971 [==============================] - 174s 180ms/step - loss: 0.0325 - acc: 0.9979 - val_loss: 0.0441 - val_acc: 0.9792\n",
      "Epoch 18/128\n",
      "971/971 [==============================] - 172s 178ms/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.0273 - val_acc: 0.9896\n",
      "Epoch 19/128\n",
      "971/971 [==============================] - 173s 178ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 0.9896\n",
      "Epoch 20/128\n",
      "971/971 [==============================] - 174s 179ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 0.9896\n",
      "Epoch 21/128\n",
      "971/971 [==============================] - 172s 177ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 0.9896\n",
      "Epoch 22/128\n",
      "971/971 [==============================] - 172s 177ms/step - loss: 0.0079 - acc: 0.9990 - val_loss: 0.0154 - val_acc: 0.9896\n",
      "Epoch 23/128\n",
      "971/971 [==============================] - 172s 177ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "Epoch 24/128\n",
      "971/971 [==============================] - 172s 177ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 25/128\n",
      "971/971 [==============================] - 174s 180ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 26/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0127 - acc: 0.9969 - val_loss: 0.0340 - val_acc: 0.9896\n",
      "Epoch 27/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0305 - val_acc: 0.9792\n",
      "Epoch 28/128\n",
      "971/971 [==============================] - 175s 181ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 29/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 1.0000\n",
      "Epoch 30/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 31/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 32/128\n",
      "971/971 [==============================] - 174s 180ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 33/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 34/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 35/128\n",
      "971/971 [==============================] - 174s 179ms/step - loss: 0.0144 - acc: 0.9959 - val_loss: 0.0469 - val_acc: 0.9688\n",
      "Epoch 36/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0158 - acc: 0.9979 - val_loss: 0.0186 - val_acc: 1.0000\n",
      "Epoch 37/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 38/128\n",
      "971/971 [==============================] - 174s 180ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 39/128\n",
      "971/971 [==============================] - 175s 181ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 40/128\n",
      "971/971 [==============================] - 174s 180ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 41/128\n",
      "971/971 [==============================] - 174s 180ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 42/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 43/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 44/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 45/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
      "Epoch 46/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 47/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 48/128\n",
      "971/971 [==============================] - 174s 179ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 49/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 50/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 51/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 52/128\n",
      "971/971 [==============================] - 173s 178ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 53/128\n",
      "971/971 [==============================] - 173s 178ms/step - loss: 9.8117e-04 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 54/128\n",
      "971/971 [==============================] - 172s 178ms/step - loss: 9.4259e-04 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 55/128\n",
      "971/971 [==============================] - 173s 178ms/step - loss: 8.9588e-04 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 56/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 8.5958e-04 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 57/128\n",
      "971/971 [==============================] - 175s 181ms/step - loss: 8.1458e-04 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 58/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 7.8252e-04 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 59/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 7.4888e-04 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 7.2471e-04 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 61/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 7.0340e-04 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 62/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 6.8294e-04 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 63/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 6.6294e-04 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 64/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 6.4418e-04 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 65/128\n",
      "971/971 [==============================] - 174s 180ms/step - loss: 6.2450e-04 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 66/128\n",
      "971/971 [==============================] - 174s 179ms/step - loss: 6.0346e-04 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 67/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 5.7997e-04 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 68/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 5.6000e-04 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 69/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 5.4479e-04 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 70/128\n",
      "971/971 [==============================] - 173s 178ms/step - loss: 5.3117e-04 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 71/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 5.1888e-04 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 72/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 5.0528e-04 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 73/128\n",
      "971/971 [==============================] - 176s 181ms/step - loss: 4.9184e-04 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 74/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 4.8053e-04 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 75/128\n",
      "971/971 [==============================] - 175s 180ms/step - loss: 4.6940e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 76/128\n",
      "896/971 [==========================>...] - ETA: 12s - loss: 4.6040e-04 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "# Run KFold\n",
    "for i in range(conf.KFOLD):\n",
    "    # Roll the data\n",
    "    for a in conf.ACTIONS:\n",
    "        xs[a] = np.roll(xs[a], int(len(xs[a]) / conf.KFOLD), axis=0)\n",
    "        ys[a] = np.roll(ys[a], int(len(ys[a]) / conf.KFOLD), axis=0)\n",
    "\n",
    "    # Data separation\n",
    "    xTrain = []\n",
    "    yTrain = []\n",
    "    xEval = []\n",
    "    yEval = []\n",
    "    for a in conf.ACTIONS:\n",
    "        if xTrain == []:\n",
    "            xTrain = xs[a][int(len(xs[a]) / conf.KFOLD):]\n",
    "        else:\n",
    "            xTrain = np.r_[xTrain, xs[a][int(len(xs[a]) / conf.KFOLD):]]\n",
    "        if yTrain == []:\n",
    "            yTrain = ys[a][int(len(ys[a]) / conf.KFOLD):]\n",
    "        else:\n",
    "            yTrain = np.r_[yTrain, ys[a][int(len(ys[a]) / conf.KFOLD):]]\n",
    "        if xEval == []:\n",
    "            xEval = xs[a][:int(len(xs[a]) / conf.KFOLD)]\n",
    "        else:\n",
    "            xEval = np.r_[xEval, xs[a][:int(len(xs[a]) / conf.KFOLD)]]\n",
    "        if yEval == []:\n",
    "            yEval = ys[a][:int(len(ys[a]) / conf.KFOLD)]\n",
    "        else:\n",
    "            yEval = np.r_[yEval, ys[a][:int(len(ys[a]) / conf.KFOLD)]]\n",
    "\n",
    "    if not conf.USE_NOACTIVITY:\n",
    "        # Remove NoActivity from ys\n",
    "        yTrain = yTrain[:, 1:]\n",
    "        yEval = yEval[:, 1:]\n",
    "\n",
    "        # If there exists only one action, convert Y to binary form\n",
    "        if yEval.shape[1] == 1:\n",
    "            yTrain = ku.to_categorical(yTrain)\n",
    "            yEval = ku.to_categorical(yEval)\n",
    "\n",
    "    # Setup Keras Checkpoint\n",
    "    checkpoint = kc.ModelCheckpoint(\n",
    "        outputDir + \"Checkpoint_K\" + str(i + 1) + \"_EPOCH{epoch}_ACC{val_acc:.6f}.h5\", period=25)\n",
    "\n",
    "    # Fit model (learn)\n",
    "    print(\n",
    "        str(i + 1) + \" th fitting started. Endpoint is \" + str(conf.KFOLD) +\n",
    "        \" th.\")\n",
    "\n",
    "    model.fit(\n",
    "        xTrain,\n",
    "        yTrain,\n",
    "        batch_size=conf.BATCH_SIZE,\n",
    "        epochs=conf.N_ITERATIONS,\n",
    "        verbose=1,\n",
    "        callbacks=[tensorboard, checkpoint],\n",
    "        validation_data=(xEval, yEval))  #, validation_freq=2)\n",
    "print(\"Epoch completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "print(\"Saving model & model information...\")\n",
    "modelYML = model.to_yaml()\n",
    "with open(outputDir + \"model.yml\", \"w\") as yml:\n",
    "    yml.write(modelYML)\n",
    "modelJSON = model.to_json()\n",
    "with open(outputDir + \"model.json\", \"w\") as json:\n",
    "    json.write(modelJSON)\n",
    "model.save(outputDir + \"model.h5\")\n",
    "print('Model saved! Congratulations! You finished all processes of ML!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finished"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

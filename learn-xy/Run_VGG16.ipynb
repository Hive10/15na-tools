{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import gc\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import progressbar as pb\n",
    "import sklearn.utils as sku\n",
    "\n",
    "import Config as conf\n",
    "import CSV as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Input directory not found. Calculate merged CSVs...\n",
      "Create window of try_8 ...\n",
      "Processing X:  ./Dataset/csi_try_8_001.csv\n",
      "Processing X:  ./Dataset/csi_try_8_002.csv\n",
      "Processing X:  ./Dataset/csi_try_8_003.csv\n",
      "Processing X:  ./Dataset/csi_try_8_004.csv\n",
      "Processing X:  ./Dataset/csi_try_8_005.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_001.csv\n",
      "Processing X:  ./Dataset/csi_try_8_006.csv\n",
      "Processing X:  ./Dataset/csi_try_8_007.csv\n",
      "Processing X:  ./Dataset/csi_try_8_008.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_002.csv\n",
      "Processing X:  ./Dataset/csi_try_8_009.csv\n",
      "Processing X:  ./Dataset/csi_try_8_010.csv\n",
      "Processing X:  ./Dataset/csi_try_8_011.csv\n",
      "Processing X:  ./Dataset/csi_try_8_012.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_003.csv\n",
      "Processing X:  ./Dataset/csi_try_8_013.csv\n",
      "Processing X:  ./Dataset/csi_try_8_014.csv\n",
      "Processing X:  ./Dataset/csi_try_8_015.csv\n",
      "Processing X:  ./Dataset/csi_try_8_016.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_004.csv\n",
      "Processing X:  ./Dataset/csi_try_8_017.csv\n",
      "Processing X:  ./Dataset/csi_try_8_018.csv\n",
      "Processing X:  ./Dataset/csi_try_8_019.csv\n",
      "Processing X:  ./Dataset/csi_try_8_020.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_005.csv\n",
      "Processing X:  ./Dataset/csi_try_8_021.csv\n",
      "Processing X:  ./Dataset/csi_try_8_022.csv\n",
      "Processing X:  ./Dataset/csi_try_8_023.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_006.csv\n",
      "Processing X:  ./Dataset/csi_try_8_024.csv\n",
      "Processing X:  ./Dataset/csi_try_8_025.csv\n",
      "Processing X:  ./Dataset/csi_try_8_026.csv\n",
      "Processing X:  ./Dataset/csi_try_8_027.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_007.csv\n",
      "Processing X:  ./Dataset/csi_try_8_028.csv\n",
      "Processing X:  ./Dataset/csi_try_8_029.csv\n",
      "Processing Y:  ./Dataset/action_try_8_001.csv\n",
      "Processing Y:  ./Dataset/action_try_8_002.csv\n",
      "Processing Y:  ./Dataset/action_try_8_003.csv\n",
      "Processing Y:  ./Dataset/action_try_8_004.csv\n",
      "Processing Y:  ./Dataset/action_try_8_005.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_001.csv\n",
      "Processing Y:  ./Dataset/action_try_8_006.csv\n",
      "Processing Y:  ./Dataset/action_try_8_007.csv\n",
      "Processing Y:  ./Dataset/action_try_8_008.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_002.csv\n",
      "Processing Y:  ./Dataset/action_try_8_009.csv\n",
      "Processing Y:  ./Dataset/action_try_8_010.csv\n",
      "Processing Y:  ./Dataset/action_try_8_011.csv\n",
      "Processing Y:  ./Dataset/action_try_8_012.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_003.csv\n",
      "Processing Y:  ./Dataset/action_try_8_013.csv\n",
      "Processing Y:  ./Dataset/action_try_8_014.csv\n",
      "Processing Y:  ./Dataset/action_try_8_015.csv\n",
      "Processing Y:  ./Dataset/action_try_8_016.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_004.csv\n",
      "Processing Y:  ./Dataset/action_try_8_017.csv\n",
      "Processing Y:  ./Dataset/action_try_8_018.csv\n",
      "Processing Y:  ./Dataset/action_try_8_019.csv\n",
      "Processing Y:  ./Dataset/action_try_8_020.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_005.csv\n",
      "Processing Y:  ./Dataset/action_try_8_021.csv\n",
      "Processing Y:  ./Dataset/action_try_8_022.csv\n",
      "Processing Y:  ./Dataset/action_try_8_023.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_006.csv\n",
      "Processing Y:  ./Dataset/action_try_8_024.csv\n",
      "Processing Y:  ./Dataset/action_try_8_025.csv\n",
      "Processing Y:  ./Dataset/action_try_8_026.csv\n",
      "Processing Y:  ./Dataset/action_try_8_027.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_007.csv\n",
      "Processing Y:  ./Dataset/action_try_8_028.csv\n",
      "Processing Y:  ./Dataset/action_try_8_029.csv\n",
      "Create window of try_10 ...\n",
      "Processing X:  ./Dataset/csi_try_10_001.csv\n",
      "Processing X:  ./Dataset/csi_try_10_002.csv\n",
      "Processing X:  ./Dataset/csi_try_10_003.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_008.csv\n",
      "Processing X:  ./Dataset/csi_try_10_004.csv\n",
      "Processing X:  ./Dataset/csi_try_10_005.csv\n",
      "Processing X:  ./Dataset/csi_try_10_006.csv\n",
      "Processing X:  ./Dataset/csi_try_10_007.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_009.csv\n",
      "Processing X:  ./Dataset/csi_try_10_008.csv\n",
      "Processing X:  ./Dataset/csi_try_10_009.csv\n",
      "Processing X:  ./Dataset/csi_try_10_010.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_010.csv\n",
      "Processing X:  ./Dataset/csi_try_10_011.csv\n",
      "Processing X:  ./Dataset/csi_try_10_012.csv\n",
      "Processing X:  ./Dataset/csi_try_10_013.csv\n",
      "Processing X:  ./Dataset/csi_try_10_014.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_011.csv\n",
      "Processing X:  ./Dataset/csi_try_10_015.csv\n",
      "Processing X:  ./Dataset/csi_try_10_016.csv\n",
      "Processing X:  ./Dataset/csi_try_10_017.csv\n",
      "Processing X:  ./Dataset/csi_try_10_018.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_012.csv\n",
      "Processing X:  ./Dataset/csi_try_10_019.csv\n",
      "Processing X:  ./Dataset/csi_try_10_020.csv\n",
      "Processing X:  ./Dataset/csi_try_10_021.csv\n",
      "Processing X:  ./Dataset/csi_try_10_022.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_013.csv\n",
      "Processing X:  ./Dataset/csi_try_10_023.csv\n",
      "Processing X:  ./Dataset/csi_try_10_024.csv\n",
      "Processing X:  ./Dataset/csi_try_10_025.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_014.csv\n",
      "Processing X:  ./Dataset/csi_try_10_026.csv\n",
      "Processing X:  ./Dataset/csi_try_10_027.csv\n",
      "Processing X:  ./Dataset/csi_try_10_028.csv\n",
      "Processing X:  ./Dataset/csi_try_10_029.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_015.csv\n",
      "Processing X:  ./Dataset/csi_try_10_030.csv\n",
      "Processing X:  ./Dataset/csi_try_10_031.csv\n",
      "Processing X:  ./Dataset/csi_try_10_032.csv\n",
      "Processing X:  ./Dataset/csi_try_10_033.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_016.csv\n",
      "Processing X:  ./Dataset/csi_try_10_034.csv\n",
      "Processing X:  ./Dataset/csi_try_10_035.csv\n",
      "Processing X:  ./Dataset/csi_try_10_036.csv\n",
      "Processing X:  ./Dataset/csi_try_10_037.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_017.csv\n",
      "Processing X:  ./Dataset/csi_try_10_038.csv\n",
      "Processing X:  ./Dataset/csi_try_10_039.csv\n",
      "Processing X:  ./Dataset/csi_try_10_040.csv\n",
      "Processing X:  ./Dataset/csi_try_10_041.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_018.csv\n",
      "Processing X:  ./Dataset/csi_try_10_042.csv\n",
      "Processing X:  ./Dataset/csi_try_10_043.csv\n",
      "Processing X:  ./Dataset/csi_try_10_044.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_019.csv\n",
      "Processing X:  ./Dataset/csi_try_10_045.csv\n",
      "Processing X:  ./Dataset/csi_try_10_046.csv\n",
      "Processing X:  ./Dataset/csi_try_10_047.csv\n",
      "Processing X:  ./Dataset/csi_try_10_048.csv\n",
      "Saving X of 200 windows: ./Input_WINDOW3760_COL90_TH85/csi_020.csv\n",
      "Processing X:  ./Dataset/csi_try_10_049.csv\n",
      "Processing X:  ./Dataset/csi_try_10_050.csv\n",
      "Processing X:  ./Dataset/csi_try_10_051.csv\n",
      "Processing Y:  ./Dataset/action_try_10_001.csv\n",
      "Processing Y:  ./Dataset/action_try_10_002.csv\n",
      "Processing Y:  ./Dataset/action_try_10_003.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_008.csv\n",
      "Processing Y:  ./Dataset/action_try_10_004.csv\n",
      "Processing Y:  ./Dataset/action_try_10_005.csv\n",
      "Processing Y:  ./Dataset/action_try_10_006.csv\n",
      "Processing Y:  ./Dataset/action_try_10_007.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_009.csv\n",
      "Processing Y:  ./Dataset/action_try_10_008.csv\n",
      "Processing Y:  ./Dataset/action_try_10_009.csv\n",
      "Processing Y:  ./Dataset/action_try_10_010.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_010.csv\n",
      "Processing Y:  ./Dataset/action_try_10_011.csv\n",
      "Processing Y:  ./Dataset/action_try_10_012.csv\n",
      "Processing Y:  ./Dataset/action_try_10_013.csv\n",
      "Processing Y:  ./Dataset/action_try_10_014.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_011.csv\n",
      "Processing Y:  ./Dataset/action_try_10_015.csv\n",
      "Processing Y:  ./Dataset/action_try_10_016.csv\n",
      "Processing Y:  ./Dataset/action_try_10_017.csv\n",
      "Processing Y:  ./Dataset/action_try_10_018.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_012.csv\n",
      "Processing Y:  ./Dataset/action_try_10_019.csv\n",
      "Processing Y:  ./Dataset/action_try_10_020.csv\n",
      "Processing Y:  ./Dataset/action_try_10_021.csv\n",
      "Processing Y:  ./Dataset/action_try_10_022.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_013.csv\n",
      "Processing Y:  ./Dataset/action_try_10_023.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Y:  ./Dataset/action_try_10_024.csv\n",
      "Processing Y:  ./Dataset/action_try_10_025.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_014.csv\n",
      "Processing Y:  ./Dataset/action_try_10_026.csv\n",
      "Processing Y:  ./Dataset/action_try_10_027.csv\n",
      "Processing Y:  ./Dataset/action_try_10_028.csv\n",
      "Processing Y:  ./Dataset/action_try_10_029.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_015.csv\n",
      "Processing Y:  ./Dataset/action_try_10_030.csv\n",
      "Processing Y:  ./Dataset/action_try_10_031.csv\n",
      "Processing Y:  ./Dataset/action_try_10_032.csv\n",
      "Processing Y:  ./Dataset/action_try_10_033.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_016.csv\n",
      "Processing Y:  ./Dataset/action_try_10_034.csv\n",
      "Processing Y:  ./Dataset/action_try_10_035.csv\n",
      "Processing Y:  ./Dataset/action_try_10_036.csv\n",
      "Processing Y:  ./Dataset/action_try_10_037.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_017.csv\n",
      "Processing Y:  ./Dataset/action_try_10_038.csv\n",
      "Processing Y:  ./Dataset/action_try_10_039.csv\n",
      "Processing Y:  ./Dataset/action_try_10_040.csv\n",
      "Processing Y:  ./Dataset/action_try_10_041.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_018.csv\n",
      "Processing Y:  ./Dataset/action_try_10_042.csv\n",
      "Processing Y:  ./Dataset/action_try_10_043.csv\n",
      "Processing Y:  ./Dataset/action_try_10_044.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_019.csv\n",
      "Processing Y:  ./Dataset/action_try_10_045.csv\n",
      "Processing Y:  ./Dataset/action_try_10_046.csv\n",
      "Processing Y:  ./Dataset/action_try_10_047.csv\n",
      "Processing Y:  ./Dataset/action_try_10_048.csv\n",
      "Saving Y of 200 windows: ./Input_WINDOW3760_COL90_TH85/action_020.csv\n",
      "Processing Y:  ./Dataset/action_try_10_049.csv\n",
      "Processing Y:  ./Dataset/action_try_10_050.csv\n",
      "Processing Y:  ./Dataset/action_try_10_051.csv\n",
      "Saving remained windows\n",
      "Saving X of 158 windows: ./Input_WINDOW3760_COL90_TH85/csi_021.csv\n",
      "Saving Y of 158 windows: ./Input_WINDOW3760_COL90_TH85/action_021.csv\n",
      "Shape notice: [xx] (4158, 3760, 90) [yy] (4158, 2)\n",
      "Calculation finished!\n",
      "CSV data automatically imported from cache.\n",
      " -- Using No-Activity window.\n",
      "Converted and Loaded CSVs.\n"
     ]
    }
   ],
   "source": [
    "# Import & shuffle CSV data\n",
    "xx, yy = csv.getCSV()\n",
    "xx, yy = sku.shuffle(xx, yy, random_state=0)\n",
    "xx = xx[..., np.newaxis]\n",
    "xo, yo = xx, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import keras.callbacks as kc\n",
    "import keras.layers as kl\n",
    "import keras.models as km\n",
    "import keras.optimizers as ko\n",
    "import keras.utils as ku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GC Collected: 0\n",
      "WARNING:tensorflow:From /home/iknowme/anaconda3/envs/ppp/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3760, 90, 1)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 3760, 90, 64)      640       \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 3760, 90, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 1880, 45, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 1880, 45, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 1880, 45, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 940, 22, 128)      0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 940, 22, 256)      295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 940, 22, 256)      590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 940, 22, 256)      590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 470, 11, 256)      0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 470, 11, 512)      1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 470, 11, 512)      2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 470, 11, 512)      2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 235, 5, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 235, 5, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 235, 5, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 235, 5, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 117, 2, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 119808)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 239618    \n",
      "=================================================================\n",
      "Total params: 14,953,154\n",
      "Trainable params: 14,953,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Setup Keras VGG16 Model\n",
    "print(\"GC Collected:\", gc.collect())\n",
    "nadam = ko.Nadam(lr=conf.LEARNING_RATE)\n",
    "vModel = VGG16(\n",
    "    input_shape=(conf.WINDOW_SIZE, conf.N_COLUMNS, 1),\n",
    "    classes=conf.USE_NOACTIVITY and conf.N_CLASSES or conf.N_VALID_CLASSES,\n",
    "    weights=None,\n",
    "    include_top=False\n",
    ")\n",
    "fltv = kl.Flatten()(vModel.output)\n",
    "dense = kl.Dense(conf.USE_NOACTIVITY and conf.N_CLASSES or conf.N_VALID_CLASSES, activation='softmax')(fltv)\n",
    "model = km.Model(inputs=vModel.input, outputs=dense)\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=nadam,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you have tensorboard in this environment, you can type below to see the result in tensorboard:\n",
      "    tensorboard --logdir=./Log_LR0.002_BATCH16_GWRRATE80/\n",
      "Keras checkpoints and final result will be saved in here:\n",
      "    ./Output_LR0.002_BATCH16_GWRRATE80/\n"
     ]
    }
   ],
   "source": [
    "# Check output directory and prepare tensorboard\n",
    "outputDir = conf.OUTPUT_PATH.format(conf.LEARNING_RATE, conf.BATCH_SIZE,\n",
    "                                    conf.N_FILTERS, \"\")\n",
    "if os.path.exists(outputDir):\n",
    "    shutil.rmtree(outputDir)\n",
    "os.makedirs(outputDir)\n",
    "logDir = conf.LOG_PATH.format(conf.LEARNING_RATE, conf.BATCH_SIZE,\n",
    "                              conf.N_FILTERS, \"\")\n",
    "if os.path.exists(logDir):\n",
    "    shutil.rmtree(logDir)\n",
    "os.makedirs(logDir)\n",
    "tensorboard = kc.TensorBoard(\n",
    "    log_dir=logDir,\n",
    "    histogram_freq=0,\n",
    "    batch_size=conf.BATCH_SIZE,\n",
    "    write_graph=True,\n",
    "    write_grads=True,\n",
    "    write_images=True,\n",
    "    update_freq=10)\n",
    "print(\n",
    "    \"If you have tensorboard in this environment, you can type below to see the result in tensorboard:\"\n",
    ")\n",
    "print(\"    tensorboard --logdir=\" + logDir)\n",
    "print(\"Keras checkpoints and final result will be saved in here:\")\n",
    "print(\"    \" + outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (4158 of 4158) |####################| Elapsed Time: 0:00:21 Time:  0:00:21\n",
      "N/A% (0 of 836) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Activity Y: 209\n",
      "Will find 836 Non-Activity windows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (836 of 836) |######################| Elapsed Time: 0:07:24 Time:  0:07:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Ratio Modified, Final Shape: [xx] (1046, 3760, 90, 1) [yy] (1046, 2)\n"
     ]
    }
   ],
   "source": [
    "# Modify activity:non-activity ratio\n",
    "conf.ANOA_RATIO = 4\n",
    "if conf.USE_NOACTIVITY:\n",
    "    xx = np.empty([0, conf.WINDOW_SIZE, conf.N_COLUMNS, 1], float)\n",
    "    yy = np.empty([0, conf.N_CLASSES], float)\n",
    "    with pb.ProgressBar(max_value=len(yo)) as bar:\n",
    "        bar.update(0)\n",
    "        for i in range(len(yo)):\n",
    "            if yo[i, 0] == 0:\n",
    "                yy = np.concatenate((yy, yo[i, :][np.newaxis, ...]), axis=0)\n",
    "                xx = np.concatenate((xx, xo[i, :][np.newaxis, ...]), axis=0)\n",
    "            bar.update(i)\n",
    "    print(\"Found Activity Y:\", len(yy))\n",
    "    noacmx = int(len(yy) * conf.ANOA_RATIO)\n",
    "    print(\"Will find\", noacmx, \"Non-Activity windows\")\n",
    "    noac = 0\n",
    "    with pb.ProgressBar(max_value=noacmx) as bar:\n",
    "        bar.update(0)\n",
    "        for i in range(len(yo)):\n",
    "            if noac > noacmx:\n",
    "                break\n",
    "            if not yo[i, 0] == 0:\n",
    "                yy = np.concatenate((yy, yo[i, :][np.newaxis, ...]), axis=0)\n",
    "                xx = np.concatenate((xx, xo[i, :][np.newaxis, ...]), axis=0)\n",
    "                bar.update(noac)\n",
    "                noac += 1\n",
    "    print(\"Input Ratio Modified, Final Shape: [xx]\", xx.shape, \"[yy]\", yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabage Collecting Time! => 10\n",
      "1 th fitting started. Endpoint is 8 th.\n",
      "WARNING:tensorflow:From /home/iknowme/anaconda3/envs/ppp/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 916 samples, validate on 130 samples\n",
      "Epoch 1/256\n",
      "916/916 [==============================] - 751s 819ms/step - loss: 3.0214 - acc: 0.8024 - val_loss: 3.4716 - val_acc: 0.7846\n",
      "Epoch 2/256\n",
      "916/916 [==============================] - 737s 804ms/step - loss: 3.1849 - acc: 0.8024 - val_loss: 3.4716 - val_acc: 0.7846\n",
      "Epoch 3/256\n",
      "916/916 [==============================] - 747s 815ms/step - loss: 3.1849 - acc: 0.8024 - val_loss: 3.4716 - val_acc: 0.7846\n",
      "Epoch 4/256\n",
      "916/916 [==============================] - 796s 869ms/step - loss: 3.1849 - acc: 0.8024 - val_loss: 3.4716 - val_acc: 0.7846\n",
      "Epoch 5/256\n",
      "832/916 [==========================>...] - ETA: 1:14 - loss: 3.0996 - acc: 0.8077"
     ]
    }
   ],
   "source": [
    "# Run KFold\n",
    "conf.KFOLD = 8\n",
    "conf.BATCH_SIZE = 64\n",
    "conf.CP_PERIOD = 1\n",
    "conf.N_EPOCH = 256\n",
    "xx, yy = sku.shuffle(xx, yy, random_state=0)\n",
    "for i in range(conf.KFOLD):\n",
    "    # Run Garbage Collector\n",
    "    print(\"Grabage Collecting Time! =>\", gc.collect())\n",
    "    \n",
    "    # Roll the data\n",
    "    xx = np.roll(xx, int(len(xx) / conf.KFOLD), axis=0)\n",
    "    yy = np.roll(yy, int(len(yy) / conf.KFOLD), axis=0)\n",
    "\n",
    "    # Data separation\n",
    "    xTrain = xx[int(len(xx) / conf.KFOLD):]\n",
    "    yTrain = yy[int(len(yy) / conf.KFOLD):]\n",
    "    xEval = xx[:int(len(xx) / conf.KFOLD)]\n",
    "    yEval = yy[:int(len(yy) / conf.KFOLD)]\n",
    "\n",
    "    if not conf.USE_NOACTIVITY:\n",
    "        # Remove NoActivity from ys\n",
    "        yTrain = yTrain[:, 1:]\n",
    "        yEval = yEval[:, 1:]\n",
    "\n",
    "        # If there exists only one action, convert Y to binary form\n",
    "        if yEval.shape[1] == 1:\n",
    "            yTrain = ku.to_categorical(yTrain)\n",
    "            yEval = ku.to_categorical(yEval)\n",
    "\n",
    "    # Setup Keras Checkpoint\n",
    "    checkpoint = kc.ModelCheckpoint(\n",
    "        outputDir + \"Checkpoint_K\" + str(i + 1) + \"_EPOCH{epoch}_ACC{val_acc:.6f}.h5\", period=conf.CP_PERIOD)\n",
    "\n",
    "    # Fit model (learn)\n",
    "    print(\n",
    "        str(i + 1) + \" th fitting started. Endpoint is \" + str(conf.KFOLD) +\n",
    "        \" th.\")\n",
    "\n",
    "    model.fit(\n",
    "        xTrain,\n",
    "        yTrain,\n",
    "        batch_size=conf.BATCH_SIZE,\n",
    "        epochs=conf.N_EPOCH,\n",
    "        verbose=1,\n",
    "        callbacks=[tensorboard, checkpoint],\n",
    "        validation_data=(xEval, yEval))  # , validation_freq=2)\n",
    "print(\"Epoch completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "print(\"Saving model & model information...\")\n",
    "modelYML = model.to_yaml()\n",
    "with open(outputDir + \"model.yml\", \"w\") as yml:\n",
    "    yml.write(modelYML)\n",
    "modelJSON = model.to_json()\n",
    "with open(outputDir + \"model.json\", \"w\") as json:\n",
    "    json.write(modelJSON)\n",
    "model.save(outputDir + \"model.h5\")\n",
    "print('Model saved! Congratulations! You finished all processes of ML!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finished"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
